{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upgrading our MNIST Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using MLDatasets\n",
    "using NPZ\n",
    "train_x, train_y = MNIST.traindata()\n",
    "test_x,  test_y  = MNIST.testdata();\n",
    "\n",
    "(images, labels) = (train_x[:,:,1:1000], train_y[1:1000])\n",
    "images = permutedims(images, (3, 2,1))\n",
    "test_x = permutedims(test_x, (3, 2,1))\n",
    "one_hot_labels = zeros(length(labels), 10)\n",
    "for (i,l) in enumerate(labels)\n",
    "    one_hot_labels[i, l+1] = 1.0\n",
    "end\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_labels = zeros((length(test_y), 10))\n",
    "\n",
    "for (i,l) in enumerate(test_y)\n",
    "    test_labels[i, l+1] = 1.0\n",
    "end\n",
    "\n",
    "using Random\n",
    "Random.seed!(1)\n",
    "\n",
    "tanh2deriv(output) = 1 - output^2\n",
    "\n",
    "function softmax(x)\n",
    "    temp = exp.(x)\n",
    "    return temp ./ sum(temp, dims=2)\n",
    "end\n",
    "\n",
    "alpha, iterations = (2, 300)\n",
    "pixels_per_image, num_labels = (784, 10)\n",
    "batch_size = 128\n",
    "\n",
    "input_rows = 28\n",
    "input_cols = 28\n",
    "\n",
    "kernel_rows = 3\n",
    "kernel_cols = 3\n",
    "num_kernels = 16\n",
    "\n",
    "hidden_size = ((input_rows - kernel_rows) * \n",
    "               (input_cols - kernel_cols)) * num_kernels\n",
    "\n",
    "kernels = 0.02 .* rand(kernel_rows*kernel_cols, num_kernels) .- 0.01\n",
    "weights_1_2 = 0.2 .* rand(hidden_size, num_labels) .- 0.1\n",
    "\n",
    "function get_image_section(layer,row_from, row_to, col_from, col_to)\n",
    "    section = layer[:, row_from:row_to,col_from:col_to]\n",
    "    return reshape(section, (:, 1, row_to-row_from+1, col_to-col_from+1))\n",
    "end\n",
    "\n",
    "\n",
    "for j=1:iterations\n",
    "    Correct_cnt = 0\n",
    "    for i = 1:batch_size:size(images, 1)-batch_size\n",
    "        batch_start, batch_end = i, i+batch_size-1\n",
    "        layer_0 = images[batch_start:batch_end,:,:]\n",
    "        \n",
    "        sects = []\n",
    "        for row_start=1:size(layer_0, 2)-kernel_rows\n",
    "            for col_start=1:size(layer_0, 3) - kernel_cols\n",
    "                sect = get_image_section(layer_0,row_start, row_start+kernel_rows-1, col_start, col_start+kernel_cols-1)\n",
    "                push!(sects, sect)\n",
    "            end\n",
    "        end\n",
    "        expanded_input = cat(sects...,dims=2)\n",
    "        es = size(expanded_input)\n",
    "        expanded_input = permutedims(expanded_input, (4,3,2,1))\n",
    "        flattened_input = reshape(expanded_input, (:,es[1]*es[2]))'\n",
    "        kernel_output = flattened_input * kernels\n",
    "        kernel_output_temp = permutedims(reshape(kernel_output', (:, es[1])), (2,1))\n",
    "        kernel_output_temp\n",
    "        layer_1 = tanh.(kernel_output_temp)\n",
    "        \n",
    "        dropout_mask = bitrand(size(layer_1))\n",
    "        layer_1 .*= dropout_mask .* 2\n",
    "        layer_2 = softmax(layer_1 * weights_1_2)\n",
    "        \n",
    "        \n",
    "        for k=1:batch_size\n",
    "            Correct_cnt += Int(argmax(layer_2[k,:]) == argmax(labels[batch_start+k-1,:]))\n",
    "        end\n",
    "        \n",
    "        layer_2_delta = (labels[batch_start:batch_end, :] .- layer_2) ./ (batch_size * size(layer_2, 1))\n",
    "        layer_1_delta = (layer_2_delta * weights_1_2') .* tanh2deriv.(layer_1)\n",
    "        layer_1_delta .*= dropout_mask\n",
    "        weights_1_2 .+= alpha .* layer_1' * layer_2_delta\n",
    "        \n",
    "        ks = size(kernel_output)\n",
    "        l1d_reshape = permutedims(reshape(layer_1_delta', (ks[2],ks[1])), (2,1))\n",
    "        k_update = flattened_input' * l1d_reshape\n",
    "        kernels .-= alpha .* k_update\n",
    "    end\n",
    "    \n",
    "    test_correct_cnt = 0\n",
    "    \n",
    "    for i=1:size(test_x, 1)\n",
    "        layer_0 = reshape(test_x[i,:,:], (1,28,28))\n",
    "        \n",
    "        sects = []\n",
    "        for row_start=1:size(layer_0, 2)-kernel_rows\n",
    "            for col_start=1:size(layer_0, 3) - kernel_cols\n",
    "                sect = get_image_section(layer_0,row_start, row_start+kernel_rows-1, col_start, col_start+kernel_cols-1)\n",
    "                push!(sects, sect)\n",
    "            end\n",
    "        end\n",
    "        expanded_input = cat(sects...,dims=2)\n",
    "        es = size(expanded_input)\n",
    "        expanded_input = permutedims(expanded_input, (4,3,2,1))\n",
    "        flattened_input = reshape(expanded_input, (:,es[1]*es[2]))'\n",
    "        kernel_output = flattened_input * kernels\n",
    "        kernel_output_temp = permutedims(reshape(kernel_output', (:, es[1])), (2,1))\n",
    "        kernel_output_temp\n",
    "        layer_1 = tanh.(kernel_output_temp)\n",
    "        \n",
    "        dropout_mask = bitrand(size(layer_1))\n",
    "        layer_1 .*= dropout_mask .* 2\n",
    "        layer_2 = softmax(layer_1 * weights_1_2)\n",
    "        test_correct_cnt += Int(argmax(dropdims(layer_2;dims=1)) == argmax(test_labels[i,:]))\n",
    "    end \n",
    "         \n",
    "    if (j%1 == 0)\n",
    "        println(\"I: $(j) Test accuracy: $(test_correct_cnt/size(test_x, 1)) Train accuracy: $(Correct_cnt/size(images, 1)) \")\n",
    "    end             \n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
